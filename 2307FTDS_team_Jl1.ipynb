{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWY7ZTq_B-oe"
   },
   "source": [
    "# EA MOVIE RECOMMENDATION Predict Student Solution\n",
    "\n",
    "© Explore Data Science Academy\n",
    "\n",
    "---\n",
    "### Honour Code\n",
    "\n",
    "I **Team, JL1**, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the [EDSA honour code](https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
    "\n",
    "Non-compliance with the honour code constitutes a material breach of contract.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLPx1XRrB-ok"
   },
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#one>1. Importing Packages</a>\n",
    "\n",
    "<a href=#two>2. Loading Data</a>\n",
    "\n",
    "<a href=#three>3. Dataset Exploration (DE)</a>\n",
    "\n",
    "<a href=#four>4. Data Cleaning</a>\n",
    "\n",
    "<a href=#four>5. Visualizations</a>\n",
    "\n",
    "<a href=#five>6. Modeling</a>\n",
    "\n",
    "<a href=#six>7. Model Performance</a>\n",
    "\n",
    "<a href=#seven>8. Model Explanations</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <a id=\"one\"></a>\n",
    "## **1. Connecting to comet**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Comet connection ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section we make a connection between comet and our jupyter notebook. |\n",
    "#### **1.1 Integrate notebook with Comet**\n",
    "\n",
    "1.1.1 <u>Install Comet Using pip and importing packages.</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: comet_ml in c:\\users\\percy\\anaconda3\\lib\\site-packages (3.35.4)\n",
      "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in c:\\users\\percy\\anaconda3\\lib\\site-packages (from comet_ml) (4.17.3)\n",
      "Requirement already satisfied: psutil>=5.6.3 in c:\\users\\percy\\anaconda3\\lib\\site-packages (from comet_ml) (5.9.0)\n",
      "Requirement already satisfied: python-box<7.0.0 in c:\\users\\percy\\anaconda3\\lib\\site-packages (from comet_ml) (6.1.0)\n",
      "Requirement already satisfied: requests-toolbelt>=0.8.0 in c:\\users\\percy\\anaconda3\\lib\\site-packages (from comet_ml) (0.9.1)\n",
      "Requirement already satisfied: requests>=2.18.4 in c:\\users\\percy\\anaconda3\\lib\\site-packages (from comet_ml) (2.29.0)\n",
      "Requirement already satisfied: semantic-version>=2.8.0 in c:\\users\\percy\\anaconda3\\lib\\site-packages (from comet_ml) (2.10.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.1.0 in c:\\users\\percy\\anaconda3\\lib\\site-packages (from comet_ml) (1.38.0)\n",
      "Requirement already satisfied: simplejson in c:\\users\\percy\\anaconda3\\lib\\site-packages (from comet_ml) (3.19.2)\n",
      "Requirement already satisfied: six in c:\\users\\percy\\anaconda3\\lib\\site-packages (from comet_ml) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in c:\\users\\percy\\anaconda3\\lib\\site-packages (from comet_ml) (1.26.16)\n",
      "Requirement already satisfied: websocket-client<1.4.0,>=0.55.0 in c:\\users\\percy\\anaconda3\\lib\\site-packages (from comet_ml) (0.58.0)\n",
      "Requirement already satisfied: wrapt>=1.11.2 in c:\\users\\percy\\anaconda3\\lib\\site-packages (from comet_ml) (1.14.1)\n",
      "Requirement already satisfied: wurlitzer>=1.0.2 in c:\\users\\percy\\anaconda3\\lib\\site-packages (from comet_ml) (3.0.3)\n",
      "Requirement already satisfied: everett[ini]<3.2.0,>=1.0.1 in c:\\users\\percy\\anaconda3\\lib\\site-packages (from comet_ml) (3.1.0)\n",
      "Requirement already satisfied: dulwich!=0.20.33,>=0.20.6 in c:\\users\\percy\\anaconda3\\lib\\site-packages (from comet_ml) (0.21.7)\n",
      "Requirement already satisfied: rich>=13.3.2 in c:\\users\\percy\\anaconda3\\lib\\site-packages (from comet_ml) (13.7.0)\n",
      "Requirement already satisfied: configobj in c:\\users\\percy\\anaconda3\\lib\\site-packages (from everett[ini]<3.2.0,>=1.0.1->comet_ml) (5.0.8)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\percy\\anaconda3\\lib\\site-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\percy\\anaconda3\\lib\\site-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.18.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\percy\\anaconda3\\lib\\site-packages (from requests>=2.18.4->comet_ml) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\percy\\anaconda3\\lib\\site-packages (from requests>=2.18.4->comet_ml) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\percy\\anaconda3\\lib\\site-packages (from requests>=2.18.4->comet_ml) (2023.5.7)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\percy\\anaconda3\\lib\\site-packages (from rich>=13.3.2->comet_ml) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\percy\\anaconda3\\lib\\site-packages (from rich>=13.3.2->comet_ml) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\percy\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet_ml) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install comet_ml\n",
    "from comet_ml import Experiment\n",
    "from comet_ml.integration.sklearn import log_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1.1 <u>Experiment Class.</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/percymmutle/dtft-team-jm1-tweets-sentiment-analysis/9edf31a3ecb543c58c20a73b0c53aea2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     C                              : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     NB1                            : MultinomialNB(alpha=0.1)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     NB1__alpha                     : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     NB1__class_prior               : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     NB1__fit_prior                 : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     NB1__force_alpha               : warn\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     NB2                            : MultinomialNB(alpha=0.1)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     NB2__alpha                     : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     NB2__class_prior               : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     NB2__fit_prior                 : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     NB2__force_alpha               : warn\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     NB3                            : MultinomialNB(alpha=0.1)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     NB3__alpha                     : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     NB3__class_prior               : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     NB3__fit_prior                 : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     NB3__force_alpha               : warn\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     algorithm                      : auto\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     alpha                          : 0.2125\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bootstrap                      : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     break_ties                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache_size                     : 200\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     ccp_alpha                      : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     class_prior                    : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     class_weight                   : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf_C                          : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf__C                         : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf__alpha                     : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf__break_ties                : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf__cache_size                : 200\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf__class_prior               : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf__class_weight              : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf__coef0                     : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf__decision_function_shape   : ovr\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf__degree                    : 3\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf__dual                      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf__fit_intercept             : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf__fit_prior                 : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf__force_alpha               : warn\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf__gamma                     : scale\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf__intercept_scaling         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf__kernel                    : rbf\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf__l1_ratio                  : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf__max_iter                  : -1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf__multi_class               : auto\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf__n_jobs                    : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf__penalty                   : l2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf__probability               : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf__random_state              : 42\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf__shrinking                 : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf__solver                    : lbfgs\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf__tol                       : 0.001\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf__verbose                   : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf__warm_start                : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf_alpha                      : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf_break_ties                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf_cache_size                 : 200\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf_class_prior                : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf_class_weight               : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf_coef0                      : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf_decision_function_shape    : ovr\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf_degree                     : 3\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf_dual                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf_fit_intercept              : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf_fit_prior                  : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf_force_alpha                : warn\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf_gamma                      : scale\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf_intercept_scaling          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf_kernel                     : rbf\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf_l1_ratio                   : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf_max_iter                   : -1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf_multi_class                : auto\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf_n_jobs                     : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf_penalty                    : l2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf_probability                : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf_random_state               : 42\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf_shrinking                  : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf_solver                     : lbfgs\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf_tol                        : 0.001\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf_verbose                    : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clf_warm_start                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     coef0                          : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_X                         : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     criterion                      : gini\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cv                             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     decision_function_shape        : ovr\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degree                         : 3\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dual                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     estimators                     : [('NB1', MultinomialNB(alpha=0.1)), ('NB2', MultinomialNB(alpha=0.1)), ('NB3', MultinomialNB(alpha=0.1))]\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     final_estimator                : RidgeClassifier(alpha=0.2125)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     final_estimator__alpha         : 0.2125\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     final_estimator__class_weight  : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     final_estimator__copy_X        : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     final_estimator__fit_intercept : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     final_estimator__max_iter      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     final_estimator__positive      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     final_estimator__random_state  : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     final_estimator__solver        : auto\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     final_estimator__tol           : 0.0001\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fit_intercept                  : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fit_prior                      : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     force_alpha                    : warn\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     gamma                          : scale\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     intercept_scaling              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kernel                         : rbf\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     l1_ratio                       : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     leaf_size                      : 30\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_depth                      : 565\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_features                   : sqrt\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_iter                       : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_leaf_nodes                 : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_samples                    : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     memory                         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metric                         : minkowski\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metric_params                  : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     min_impurity_decrease          : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     min_samples_leaf               : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     min_samples_split              : 2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     min_weight_fraction_leaf       : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_class                    : auto\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     n_estimators                   : 125\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     n_jobs                         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     n_neighbors                    : 5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     neg_label                      : -1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     norm                           : l2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     oob_score                      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     p                              : 2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     passthrough                    : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     penalty                        : l2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pos_label                      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     positive                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     probability                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     random_state                   : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shrinking                      : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     smooth_idf                     : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     solver                         : auto\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     sparse_output                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     splitter                       : best\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stack_method                   : auto\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     sublinear_tf                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf__analyzer                : char\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf__binary                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf__decode_error            : strict\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf__dtype                   : <class 'numpy.float64'>\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf__encoding                : utf-8\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf__input                   : content\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf__lowercase               : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf__max_df                  : 0.9\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf__max_features            : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf__min_df                  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf__ngram_range             : (1, 5)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf__norm                    : l2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf__preprocessor            : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf__smooth_idf              : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf__stop_words              : english\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf__strip_accents           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf__sublinear_tf            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf__token_pattern           : (?u)\\b\\w\\w+\\b\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf__tokenizer               : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf__use_idf                 : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf__vocabulary              : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf_analyzer                 : char\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf_binary                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf_decode_error             : strict\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf_dtype                    : <class 'numpy.float64'>\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf_encoding                 : utf-8\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf_input                    : content\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf_lowercase                : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf_max_df                   : 0.9\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf_max_features             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf_min_df                   : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf_ngram_range              : (1, 5)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf_norm                     : l2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf_preprocessor             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf_smooth_idf               : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf_stop_words               : english\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf_strip_accents            : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf_sublinear_tf             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf_token_pattern            : (?u)\\b\\w\\w+\\b\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf_tokenizer                : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf_use_idf                  : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tfidf_vocabulary               : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tol                            : 0.0001\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     use_idf                        : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose                        : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warm_start                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weights                        : uniform\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-environment-definition : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-info                   : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-specification          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed)     : 1 (6.73 MB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages           : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code                  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;196mCOMET ERROR:\u001b[0m Error sending a notification, make sure you have opted-in for notifications\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/percymmutle/dtft-team-jm1-tweets-sentiment-analysis/7c1ea6518e3d402aa04923fe21a81bb5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from comet_ml import Experiment\n",
    "from comet_ml.integration.sklearn import log_model\n",
    "\n",
    "experiment = Experiment(\n",
    "  api_key=\"jaCCoM7qyMiPJsNULnGRCIUOG\",\n",
    "  project_name=\"dtft-team-jm1-tweets-sentiment-analysis\",\n",
    "  workspace=\"percymmutle\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Build your model and fit\\n# ...\\n# clf.fit(X_train_scaled, y_train)\\n    \\nexperiment.log_parameters(params)\\nexperiment.log_metrics(metrics)\\n\\n# Seamlessly log your SKLearn model\\nlog_model(experiment, \"TheModel\", clf)'"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Build your model and fit\n",
    "# ...\n",
    "# clf.fit(X_train_scaled, y_train)\n",
    "    \n",
    "experiment.log_parameters(params)\n",
    "experiment.log_metrics(metrics)\n",
    "\n",
    "# Seamlessly log your SKLearn model\n",
    "log_model(experiment, \"TheModel\", clf)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhy8Fx7KB-ol"
   },
   "source": [
    " <a id=\"one\"></a>\n",
    "## **2. Introduction**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Project Brief ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section we give a brief introduction of the project. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gDjM4ymB-om"
   },
   "source": [
    "### Predict Overview: EA Movie Recommendation.\n",
    "\n",
    "In today’s technology driven world, recommender systems are socially and economically critical for ensuring that individuals can make appropriate choices surrounding the content they engage with on a daily basis. One application where this is especially true surrounds movie content recommendations; where intelligent algorithms can help viewers find great titles from tens of thousands of options.\n",
    "\n",
    "ever wondered how Netflix, Amazon Prime, Showmax, Disney and the likes somehow know what to recommend to you?\n",
    "\n",
    "it's not just a guess drawn out of the hat. There is an algorithm behind it.\n",
    "With this context, EA is challenging you to construct a recommendation algorithm based on content or collaborative filtering, capable of accurately predicting how a user will rate a movie they have not yet viewed based on their historical preferences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5fdFDyGB-om"
   },
   "source": [
    " <a id=\"one\"></a>\n",
    "## **3. Importing Packages**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Importing Packages ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section we import, and briefly discuss, the libraries that will be used throughout our analysis and modelling. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jFxWX8POB-on"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\percy\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: click in c:\\users\\percy\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\percy\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\percy\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\percy\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\percy\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\percy\\anaconda3\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: wordcloud in c:\\users\\percy\\anaconda3\\lib\\site-packages (1.9.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\percy\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\percy\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\percy\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\percy\\anaconda3\\lib\\site-packages (from wordcloud) (9.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\percy\\anaconda3\\lib\\site-packages (from wordcloud) (3.7.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\percy\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\percy\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\percy\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\percy\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\percy\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\percy\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (23.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\percy\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "# Libraries for data loading, data manipulation and data visulisation\n",
    "!pip install nltk\n",
    "!pip install pandas wordcloud\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer\n",
    "import re\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "import seaborn as sns\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer\n",
    "import pickle\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Libraries for data preparation and model building\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tx4iAdQRB-oq"
   },
   "source": [
    "<a id=\"two\"></a>\n",
    "## **3. Loading the Data**\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Loading the data ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section we load the data from the data we are working with on the notebook. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1cirAAl1B-or"
   },
   "source": [
    "#### **3.1 Loading the dataset into the notebook**\n",
    "- The train and the test datasets are loaded into the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tT83iJbcB-ot"
   },
   "outputs": [],
   "source": [
    "# Loading train_df\n",
    "df_movie = pd.read_csv('movies.csv')\n",
    "# Loading test_df\n",
    "df_rating = pd.read_csv('ratings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6mj2C0JB-ou"
   },
   "source": [
    "#### **3.2 Checking the loaded data**\n",
    "- Observing the first 5 raws of the df_test and df_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "CtQqnL-EB-ov"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Any lookout's\n",
    "df_movie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "7hI84c3VB-ow"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1       31     2.5  1260759144\n",
       "1       1     1029     3.0  1260759179\n",
       "2       1     1061     3.0  1260759182\n",
       "3       1     1129     2.0  1260759185\n",
       "4       1     1172     4.0  1260759205"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Any lookout's\n",
    "df_rating.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"five\"></a>\n",
    "## **4. Feature Engineering**\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Modelling ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, we create new features. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vl-VOXD5B-ox"
   },
   "source": [
    "<a id=\"four\"></a>\n",
    "## **4. Data Cleaning**\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Data engineering ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section: We clean the dataset, and possibly create new features.|\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reason:** Text cleaning, also known as text preprocessing, is the essential process of refining raw text data for effective analysis in natural language processing and machine learning. It involves various techniques such as lowercasing, tokenization, removing special characters, punctuation, and stopwords, stemming or lemmatization, and addressing issues like URLs and HTML tags. The objective is to transform raw text into a structured and standardized format, reducing noise and ensuring consistency, ultimately enhancing the accuracy and efficiency of downstream NLP and machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zY25H28YB-pH"
   },
   "source": [
    "<a id=\"three\"></a>\n",
    "## **5. Exploratory Data Analysis (EDA)**\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Exploratory data analysis ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, we perform explore the data in the DataFrame. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-deMe4GB-pa"
   },
   "source": [
    "<a id=\"six\"></a>\n",
    "## **7. Model Performance**\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model performance ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section we compare the relative performance of the various trained ML models on a holdout dataset and comment on them. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q3h1xoeFB-pd"
   },
   "source": [
    "\n",
    "# <a href=#cont> **THE END**</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "INazgQXrB-pd"
   },
   "source": [
    "## **Authors**\n",
    "\n",
    "| Name | Surname | Position |\n",
    "| :----------- | :------------: | ------------: |\n",
    "| Percy  | Mmutle       | Team Leader       |\n",
    "| Dakalo   | Modimeli       | Team Admin       |\n",
    "| Sinothabo| Zwane      | Project Admin   |\n",
    "| Katlego| Mbewe | Admin|\n",
    "|Ntombenhle| Nkosi | Research |\n",
    "|Ivan | Cronje |"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
